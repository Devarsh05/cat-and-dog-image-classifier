{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la_Oz6oLlub6"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  # This command only in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaF8r6aOl48C",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Get project files\n",
        "!wget https://cdn.freecodecamp.org/project-data/cats-and-dogs/cats_and_dogs.zip\n",
        "\n",
        "!unzip cats_and_dogs.zip\n",
        "\n",
        "PATH = 'cats_and_dogs'\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "test_dir = os.path.join(PATH, 'test')\n",
        "\n",
        "# Get number of files in each directory. The train and validation directories\n",
        "# each have the subdirecories \"dogs\" and \"cats\".\n",
        "total_train = sum([len(files) for r, d, files in os.walk(train_dir)])\n",
        "total_val = sum([len(files) for r, d, files in os.walk(validation_dir)])\n",
        "total_test = len(os.listdir(test_dir))\n",
        "\n",
        "# Variables for pre-processing and training.\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOJFeEfumns6"
      },
      "outputs": [],
      "source": [
        "# 3\n",
        "\n",
        "# Create ImageDataGenerator instances for train, validation, and test datasets.\n",
        "# Rescale pixel values from [0, 255] → [0, 1].\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Generate batches of image data (and labels) directly from directory structures.\n",
        "train_data_gen = train_image_generator.flow_from_directory(\n",
        "    directory=train_dir,\n",
        "    batch_size=batch_size,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    class_mode='binary'   # two classes: cats and dogs\n",
        ")\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(\n",
        "    directory=validation_dir,\n",
        "    batch_size=batch_size,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# For the test set: there are no subfolders (no labels).\n",
        "# We use flow_from_directory trick by pointing to a parent folder and\n",
        "# passing shuffle=False to preserve order.\n",
        "test_data_gen = test_image_generator.flow_from_directory(\n",
        "    directory=PATH,                # parent folder that contains 'test'\n",
        "    classes=['test'],              # explicitly choose only 'test' subfolder\n",
        "    batch_size=batch_size,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    class_mode=None,               # no labels for test data\n",
        "    shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TP0WA8j1mt7Q"
      },
      "outputs": [],
      "source": [
        "# Define a function to visualize a batch of images\n",
        "def plotImages(images_arr, probabilities = False):\n",
        "    # Create a figure with one subplot per image\n",
        "    fig, axes = plt.subplots(len(images_arr), 1, figsize=(5, len(images_arr) * 3))\n",
        "\n",
        "    # If no probabilities provided, just display images\n",
        "    if probabilities is False:\n",
        "        for img, ax in zip(images_arr, axes):\n",
        "            ax.imshow(img)\n",
        "            ax.axis('off')\n",
        "    else:\n",
        "        # Display images with probability titles\n",
        "        for img, probability, ax in zip(images_arr, probabilities, axes):\n",
        "            ax.imshow(img)\n",
        "            ax.axis('off')\n",
        "            if probability > 0.5:\n",
        "                ax.set_title(\"%.2f\" % (probability*100) + \"% dog\")\n",
        "            else:\n",
        "                ax.set_title(\"%.2f\" % ((1-probability)*100) + \"% cat\")\n",
        "    plt.show()\n",
        "\n",
        "# Extract one batch of training images and labels from the generator\n",
        "sample_training_images, _ = next(train_data_gen)\n",
        "\n",
        "# Plot first five images from that batch\n",
        "plotImages(sample_training_images[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-32RRLY_3voj"
      },
      "outputs": [],
      "source": [
        "# 5\n",
        "\n",
        "train_image_generator = ImageDataGenerator(\n",
        "    rescale=1./255,            # (1) normalization — always include this\n",
        "    rotation_range=40,         # (2) random rotations up to 40 degrees\n",
        "    width_shift_range=0.2,     # (3) horizontal shifts\n",
        "    height_shift_range=0.2,    # (4) vertical shifts\n",
        "    shear_range=0.2,           # (5) shear transformations\n",
        "    zoom_range=0.2,            # (6) random zoom in/out\n",
        "    horizontal_flip=True,      # (7) flip images horizontally\n",
        "    fill_mode='nearest'        # handles empty pixels created by transformations\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkwq2LFvqabS"
      },
      "outputs": [],
      "source": [
        "# 6\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "\n",
        "plotImages(augmented_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8aZkwMam4UY"
      },
      "outputs": [],
      "source": [
        "# 7\n",
        "\n",
        "model = Sequential([\n",
        "\n",
        "    # --- Convolution + Pooling Layers ---\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    # --- Flatten + Dense Layers ---\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),                   # helps reduce overfitting\n",
        "    Dense(1, activation='sigmoid')  # binary classification (cat vs. dog)\n",
        "])\n",
        "\n",
        "# --- Compile the Model ---\n",
        "model.compile(\n",
        "    optimizer='adam',                     # good general-purpose optimizer\n",
        "    loss='binary_crossentropy',           # binary classification loss\n",
        "    metrics=['accuracy']                  # track accuracy during training\n",
        ")\n",
        "\n",
        "# --- Show Model Summary ---\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1niQDz5x6K7y"
      },
      "outputs": [],
      "source": [
        "# 8\n",
        "\n",
        "# Train the model using the fit method\n",
        "history = model.fit(\n",
        "    x=train_data_gen,                        # training data generator\n",
        "    steps_per_epoch=total_train // batch_size,  # number of batches per epoch\n",
        "    epochs=epochs,                           # how many times to go through the data\n",
        "    validation_data=val_data_gen,            # validation data generator\n",
        "    validation_steps=total_val // batch_size # number of validation batches per epoch\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xS51mB56OAC"
      },
      "outputs": [],
      "source": [
        "# 9\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYrSifOit2aK"
      },
      "outputs": [],
      "source": [
        "# 10\n",
        "\n",
        "# Use the trained model to predict probabilities on the test dataset\n",
        "probabilities = model.predict(test_data_gen)\n",
        "\n",
        "# Visualize the test images with their predicted probabilities\n",
        "plotImages(test_data_gen[0][0][:50], probabilities[:50])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwtcAnOEJ5Vs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IH86Ux_u7TZ"
      },
      "outputs": [],
      "source": [
        "# 11\n",
        "answers =  [1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
        "            1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
        "            1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
        "            1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
        "            0, 0, 0, 0, 0, 0]\n",
        "\n",
        "correct = 0\n",
        "\n",
        "for probability, answer in zip(probabilities, answers):\n",
        "  if round(probability[0]) == answer:\n",
        "    correct +=1\n",
        "\n",
        "percentage_identified = (correct / len(answers)) * 100\n",
        "\n",
        "passed_challenge = percentage_identified >= 63\n",
        "\n",
        "print(f\"Your model correctly identified {round(percentage_identified, 2)}% of the images of cats and dogs.\")\n",
        "\n",
        "if passed_challenge:\n",
        "  print(\"You passed the challenge!\")\n",
        "else:\n",
        "  print(\"You haven't passed yet. Your model should identify at least 63% of the images. Keep trying. You will get it!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "fcc_cat_dog.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}